{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\n\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torch.utils.data import DataLoader, TensorDataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-30T03:51:53.152945Z","iopub.execute_input":"2023-11-30T03:51:53.154625Z","iopub.status.idle":"2023-11-30T03:51:53.163119Z","shell.execute_reply.started":"2023-11-30T03:51:53.154559Z","shell.execute_reply":"2023-11-30T03:51:53.161343Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:51:53.185713Z","iopub.execute_input":"2023-11-30T03:51:53.188245Z","iopub.status.idle":"2023-11-30T03:51:53.897623Z","shell.execute_reply.started":"2023-11-30T03:51:53.188191Z","shell.execute_reply":"2023-11-30T03:51:53.896299Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:51:53.899908Z","iopub.execute_input":"2023-11-30T03:51:53.900385Z","iopub.status.idle":"2023-11-30T03:51:53.928763Z","shell.execute_reply.started":"2023-11-30T03:51:53.900351Z","shell.execute_reply":"2023-11-30T03:51:53.927177Z"},"trusted":true},"execution_count":154,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50000 entries, 0 to 49999\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   review     50000 non-null  object\n 1   sentiment  50000 non-null  object\ndtypes: object(2)\nmemory usage: 781.4+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:51:53.930184Z","iopub.execute_input":"2023-11-30T03:51:53.930564Z","iopub.status.idle":"2023-11-30T03:51:53.942565Z","shell.execute_reply.started":"2023-11-30T03:51:53.930533Z","shell.execute_reply":"2023-11-30T03:51:53.941200Z"},"trusted":true},"execution_count":155,"outputs":[{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.sentiment = df.sentiment.apply(lambda x: 0 if x == \"positive\" else 1)\ndf.review = df.review.apply(lambda x: \" \".join(re.sub(r\"[^A-Za-z0-9]+\", \" \", x.lower()).split()))","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:51:53.945306Z","iopub.execute_input":"2023-11-30T03:51:53.945800Z","iopub.status.idle":"2023-11-30T03:52:02.148043Z","shell.execute_reply.started":"2023-11-30T03:51:53.945744Z","shell.execute_reply":"2023-11-30T03:52:02.146692Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"train = df.sample(frac=0.8, random_state=3)\nval = df.drop(train.index)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:52:02.149981Z","iopub.execute_input":"2023-11-30T03:52:02.150532Z","iopub.status.idle":"2023-11-30T03:52:02.185834Z","shell.execute_reply.started":"2023-11-30T03:52:02.150481Z","shell.execute_reply":"2023-11-30T03:52:02.184653Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"train = train.reset_index(drop=True)\nval = val.reset_index(drop=True)\n\nprint(train.shape[0], val.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:52:02.188267Z","iopub.execute_input":"2023-11-30T03:52:02.188755Z","iopub.status.idle":"2023-11-30T03:52:02.202160Z","shell.execute_reply.started":"2023-11-30T03:52:02.188712Z","shell.execute_reply":"2023-11-30T03:52:02.200856Z"},"trusted":true},"execution_count":158,"outputs":[{"name":"stdout","text":"40000 10000\n","output_type":"stream"}]},{"cell_type":"code","source":"class BaselineModel(nn.Module):\n    def __init__(self, vocab_size, seq_len, embed_dim):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.flatten = nn.Flatten()\n        self.fc_out = nn.Linear(in_features=embed_dim * seq_len, out_features=1)\n    \n    def forward(self, x):\n        x = self.embedding(x)\n        x = self.flatten(x)\n        x = self.fc_out(x)\n        return x.unsqueeze(-1)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:54:24.204396Z","iopub.execute_input":"2023-11-30T03:54:24.206059Z","iopub.status.idle":"2023-11-30T03:54:24.214800Z","shell.execute_reply.started":"2023-11-30T03:54:24.205992Z","shell.execute_reply":"2023-11-30T03:54:24.213832Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"def crude_tokenizer(corpus: list[str]):\n    word_to_idx = {}\n    counter = 1\n    \n    for sentences in corpus:\n        words = sentences.split()\n        for word in words:\n            if word not in word_to_idx.keys():\n                word_to_idx[word] = counter\n                counter +=1\n                \n    return word_to_idx","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:52:02.215997Z","iopub.execute_input":"2023-11-30T03:52:02.216634Z","iopub.status.idle":"2023-11-30T03:52:02.225820Z","shell.execute_reply.started":"2023-11-30T03:52:02.216596Z","shell.execute_reply":"2023-11-30T03:52:02.224482Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"tokenizer_dict = crude_tokenizer(train.review.values)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:52:02.227449Z","iopub.execute_input":"2023-11-30T03:52:02.228125Z","iopub.status.idle":"2023-11-30T03:52:05.113018Z","shell.execute_reply.started":"2023-11-30T03:52:02.228090Z","shell.execute_reply":"2023-11-30T03:52:05.111756Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"tokenized_train = list(map(lambda x: [tokenizer_dict[y] for y in x if y != ' '], train.review.values))\ntokenized_val = list(map(lambda x: [tokenizer_dict[y] for y in x if y != ' '], val.review.values))","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:52:05.118312Z","iopub.execute_input":"2023-11-30T03:52:05.118713Z","iopub.status.idle":"2023-11-30T03:52:14.448310Z","shell.execute_reply.started":"2023-11-30T03:52:05.118679Z","shell.execute_reply":"2023-11-30T03:52:14.447069Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"code","source":"# Get min and max sequence length\n\nmax([len(x) for x in tokenized_train])\n\n# Lets just cap it at 1024 and left-pad to there","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:52:14.450490Z","iopub.execute_input":"2023-11-30T03:52:14.450947Z","iopub.status.idle":"2023-11-30T03:52:14.464696Z","shell.execute_reply.started":"2023-11-30T03:52:14.450912Z","shell.execute_reply":"2023-11-30T03:52:14.463328Z"},"trusted":true},"execution_count":163,"outputs":[{"execution_count":163,"output_type":"execute_result","data":{"text/plain":"10877"},"metadata":{}}]},{"cell_type":"code","source":"itd = [i for i, _ in enumerate(tokenized_train) if len(_) > 1024]\n\ntokenized_train = [x for x in tokenized_train if len(x) <= 1024]\ntrain = train.drop(itd).reset_index(drop=True)\n\nmax([len(x) for x in tokenized_train])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:52:14.466208Z","iopub.execute_input":"2023-11-30T03:52:14.466646Z","iopub.status.idle":"2023-11-30T03:52:14.595540Z","shell.execute_reply.started":"2023-11-30T03:52:14.466615Z","shell.execute_reply":"2023-11-30T03:52:14.594656Z"},"trusted":true},"execution_count":164,"outputs":[{"execution_count":164,"output_type":"execute_result","data":{"text/plain":"1024"},"metadata":{}}]},{"cell_type":"code","source":"itd = [i for i, _ in enumerate(tokenized_val) if len(_) > 1024]\n\ntokenized_val = [x for x in tokenized_val if len(x) <= 1024]\nval = val.drop(itd).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:52:14.596713Z","iopub.execute_input":"2023-11-30T03:52:14.597949Z","iopub.status.idle":"2023-11-30T03:52:14.634795Z","shell.execute_reply.started":"2023-11-30T03:52:14.597911Z","shell.execute_reply":"2023-11-30T03:52:14.633848Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"# padding\n\ndef left_pad_sequences(sequences, target_length, padding_value=0):\n    \"\"\"\n    Left pads each sequence in the list of sequences with the padding_value\n    to ensure each sequence has the same length, which is target_length.\n\n    :param sequences: List of lists, where each inner list is a sequence.\n    :param target_length: The desired length for all sequences.\n    :param padding_value: The value to use for padding. Default is 0.\n    :return: List of sequences, all of the same length.\n    \"\"\"\n    padded_sequences = []\n    for sequence in sequences:\n        # Calculate the number of padding elements needed\n        padding_length = max(0, target_length - len(sequence))\n        # Create the padded sequence and add it to the result list\n        padded_sequence = [padding_value] * padding_length + sequence\n        padded_sequences.append(padded_sequence)\n    \n    return padded_sequences","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:52:14.636052Z","iopub.execute_input":"2023-11-30T03:52:14.636601Z","iopub.status.idle":"2023-11-30T03:52:14.647791Z","shell.execute_reply.started":"2023-11-30T03:52:14.636570Z","shell.execute_reply":"2023-11-30T03:52:14.646657Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"train_tokens_padded = left_pad_sequences(tokenized_train, 1024)\nval_tokens_padded = left_pad_sequences(tokenized_val, 1024)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:52:14.649051Z","iopub.execute_input":"2023-11-30T03:52:14.649403Z","iopub.status.idle":"2023-11-30T03:52:15.905688Z","shell.execute_reply.started":"2023-11-30T03:52:14.649373Z","shell.execute_reply":"2023-11-30T03:52:15.904429Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(\n    dataset=TensorDataset(torch.tensor(train_tokens_padded, dtype=torch.int64), torch.tensor(train.sentiment.values, dtype=torch.float32)),\n    shuffle=True,\n    batch_size=8\n)\n\nval_loader = DataLoader(\n    dataset=TensorDataset(torch.tensor(val_tokens_padded, dtype=torch.int64), torch.tensor(val.sentiment.values, dtype=torch.float32)),\n    shuffle=False,\n    batch_size=16\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:52:15.907443Z","iopub.execute_input":"2023-11-30T03:52:15.907794Z","iopub.status.idle":"2023-11-30T03:52:21.285112Z","shell.execute_reply.started":"2023-11-30T03:52:15.907751Z","shell.execute_reply":"2023-11-30T03:52:21.283878Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"def train_on_epoch(epoch, model, optimizer, criterion, loader, device):\n    model.train()\n    running_loss = 0.\n    running_accuracy = 0.\n    \n    for step, (tokens, labels) in enumerate(loader):\n        tokens = tokens.to(device)\n        labels = labels.unsqueeze(-1).to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(tokens)\n                \n        loss = criterion(outputs.squeeze(-1), labels)\n        \n        optimizer.step()\n        \n        # Just for good measure\n        \n        with torch.no_grad():\n            running_loss += loss\n            \n            print(f\"Epoch {epoch + 1} -- step {step + 1} -- bce_loss: {running_loss / (step + 1)}\", end=\"\\r\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:54:30.509979Z","iopub.execute_input":"2023-11-30T03:54:30.511352Z","iopub.status.idle":"2023-11-30T03:54:30.522453Z","shell.execute_reply.started":"2023-11-30T03:54:30.511302Z","shell.execute_reply":"2023-11-30T03:54:30.520762Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"def validate_epoch(epoch, model, optimizer, criterion, loader, device):\n    model.eval()\n    \n    with torch.no_grad():\n        running_loss = 0.\n\n        for step, (tokens, labels) in enumerate(loader):\n            tokens = tokens.to(device)\n            labels = labels.unsqueeze(-1).to(device)\n\n            outputs = model(tokens)\n\n            loss = criterion(outputs.squeeze(-1), labels)\n            running_loss += loss\n\n        print(f\"Validation Epoch {epoch + 1} -- val_bce_loss: {running_loss / len(loader)}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:54:30.642328Z","iopub.execute_input":"2023-11-30T03:54:30.643154Z","iopub.status.idle":"2023-11-30T03:54:30.652240Z","shell.execute_reply.started":"2023-11-30T03:54:30.643100Z","shell.execute_reply":"2023-11-30T03:54:30.650827Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"bm = BaselineModel(len(tokenizer_dict.keys()), 1024, 64)\noptimizer = optim.Adam(bm.parameters(), lr=1e-4)\ncriterion = nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:54:30.763499Z","iopub.execute_input":"2023-11-30T03:54:30.764444Z","iopub.status.idle":"2023-11-30T03:54:30.825539Z","shell.execute_reply.started":"2023-11-30T03:54:30.764392Z","shell.execute_reply":"2023-11-30T03:54:30.824486Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"for epoch in range(25):\n    train_on_epoch(epoch, bm, optimizer, criterion, train_loader, \"cpu\")\n    validate_epoch(epoch, bm, optimizer, criterion, val_loader, \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:54:31.303169Z","iopub.execute_input":"2023-11-30T03:54:31.303920Z","iopub.status.idle":"2023-11-30T03:55:00.020016Z","shell.execute_reply.started":"2023-11-30T03:54:31.303882Z","shell.execute_reply":"2023-11-30T03:55:00.018149Z"},"trusted":true},"execution_count":199,"outputs":[{"name":"stdout","text":"Epoch 1 -- step 3330 -- bce_loss: 0.7177275419235236\nValidation Epoch 1 -- val_bce_loss: 0.7176714539527893\nEpoch 2 -- step 3330 -- bce_loss: 0.7177346348762512\nValidation Epoch 2 -- val_bce_loss: 0.7176714539527893\nEpoch 3 -- step 3330 -- bce_loss: 0.7177257537841797\nValidation Epoch 3 -- val_bce_loss: 0.7176714539527893\nEpoch 4 -- step 3330 -- bce_loss: 0.7177298069000244\nValidation Epoch 4 -- val_bce_loss: 0.7176714539527893\nEpoch 5 -- step 3330 -- bce_loss: 0.7177303433418274\nValidation Epoch 5 -- val_bce_loss: 0.7176714539527893\nEpoch 6 -- step 3330 -- bce_loss: 0.7177314758300781\nValidation Epoch 6 -- val_bce_loss: 0.7176714539527893\nEpoch 7 -- step 3330 -- bce_loss: 0.7177283763885498\nValidation Epoch 7 -- val_bce_loss: 0.7176714539527893\nEpoch 8 -- step 3330 -- bce_loss: 0.7177239656448364\nValidation Epoch 8 -- val_bce_loss: 0.7176714539527893\nEpoch 9 -- step 675 -- bce_loss: 0.7146227359771729\r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[199], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m25\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain_on_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     validate_epoch(epoch, bm, optimizer, criterion, val_loader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[196], line 16\u001b[0m, in \u001b[0;36mtrain_on_epoch\u001b[0;34m(epoch, model, optimizer, criterion, loader, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(tokens)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), labels)\n\u001b[0;32m---> 16\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Just for good measure\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:265\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprofile_hook_step\u001b[39m(func):\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m    268\u001b[0m         profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"class LayerOfSin(nn.Module):\n    def __init__(self, input_sz, output_sz):\n        super(LayerOfSin, self).__init__()\n        self.amplitude = nn.Parameter(torch.randn(output_sz, 1))\n        self.phase = nn.Parameter(torch.randn(input_sz, output_sz))\n        self.bias = nn.Parameter(torch.ones(output_sz,))\n\n    def forward(self, x):\n        x = torch.sin(x @ self.phase)\n        x = x @ self.amplitude + self.bias\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:52:51.871913Z","iopub.execute_input":"2023-11-30T03:52:51.873158Z","iopub.status.idle":"2023-11-30T03:52:51.881383Z","shell.execute_reply.started":"2023-11-30T03:52:51.873107Z","shell.execute_reply":"2023-11-30T03:52:51.880104Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"code","source":"class LayerOfCos(nn.Module):\n    def __init__(self, input_sz, output_sz):\n        super(LayerOfCos, self).__init__()\n        self.amplitude = nn.Parameter(torch.randn(output_sz, 1))\n        self.phase = nn.Parameter(torch.randn(input_sz, output_sz))\n        self.bias = nn.Parameter(torch.ones(output_sz,))\n\n    def forward(self, x):\n        x = torch.cos(x @ self.phase)\n        x = x @ self.amplitude + self.bias\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:52:51.993518Z","iopub.execute_input":"2023-11-30T03:52:51.994014Z","iopub.status.idle":"2023-11-30T03:52:52.002873Z","shell.execute_reply.started":"2023-11-30T03:52:51.993977Z","shell.execute_reply":"2023-11-30T03:52:52.001236Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"code","source":"class TrigonometricModel(nn.Module):\n    def __init__(self, vocab_size, seq_len, embed_dim):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.pos_encoding = nn.Embedding(seq_len, embed_dim)\n        self.seq_len = seq_len\n        self.lsin_1 = LayerOfSin(seq_len, 128)\n        self.lcos_1 = LayerOfCos(embed_dim, 128)\n        self.lsin_2 = LayerOfSin(embed_dim, 128)\n        self.lcos_2 = LayerOfCos(seq_len, 128)\n        self.conv = nn.Conv1d(in_channels=128, out_channels=1, kernel_size=2)\n        self.ln = nn.LayerNorm(4)\n        self.linear = nn.Linear(3, 1)\n    \n    def forward(self, x):\n        x_e = self.embedding(x)\n        \n        pos = torch.arange(start=0, end=self.seq_len, device=x.device)\n        \n        encoded = self.pos_encoding(pos).repeat(x_e.shape[0], 1, 1)\n                                \n        x_a = self.lsin_1(x_e[:, :, :1].squeeze(-1))\n        x_b = self.lcos_1(x_e[:, :1, :].squeeze(1))\n        \n        x_c = self.lcos_2(encoded[:, :, :1].squeeze(-1))\n        x_d = self.lsin_2(encoded[:, :1, :].squeeze(1))\n        \n        stacked = torch.stack([x_a, x_b, x_c, x_d], dim=-1)\n        normed = self.ln(stacked)\n        \n        normed = self.conv(normed)\n                \n        return self.linear(normed)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:56:37.780704Z","iopub.execute_input":"2023-11-30T03:56:37.781956Z","iopub.status.idle":"2023-11-30T03:56:37.796308Z","shell.execute_reply.started":"2023-11-30T03:56:37.781914Z","shell.execute_reply":"2023-11-30T03:56:37.795025Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"tm = TrigonometricModel(len(tokenizer_dict.keys()), 1024, 32)\noptimizer = optim.SGD(tm.parameters(), lr=1e-3)\ncriterion = nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:57:11.718467Z","iopub.execute_input":"2023-11-30T03:57:11.718898Z","iopub.status.idle":"2023-11-30T03:57:11.756448Z","shell.execute_reply.started":"2023-11-30T03:57:11.718866Z","shell.execute_reply":"2023-11-30T03:57:11.755209Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"for epoch in range(25):\n    train_on_epoch(epoch, tm, optimizer, criterion, train_loader, \"cpu\")\n    validate_epoch(epoch, tm, optimizer, criterion, val_loader, \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-11-30T03:57:11.845933Z","iopub.execute_input":"2023-11-30T03:57:11.846339Z","iopub.status.idle":"2023-11-30T03:57:19.427563Z","shell.execute_reply.started":"2023-11-30T03:57:11.846310Z","shell.execute_reply":"2023-11-30T03:57:19.425886Z"},"trusted":true},"execution_count":204,"outputs":[{"name":"stdout","text":"Epoch 1 -- step 535 -- bce_loss: 0.7133740782737732\r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[204], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m25\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain_on_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     validate_epoch(epoch, tm, optimizer, criterion, val_loader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[196], line 6\u001b[0m, in \u001b[0;36mtrain_on_epoch\u001b[0;34m(epoch, model, optimizer, criterion, loader, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m      4\u001b[0m running_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (tokens, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m      7\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    204\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Given I only had < 2-3 hours to port over my idea of using sine waves as\n# I have succesfully applied to basic regression, I figured the challenge\n# may exceed the time needed although I am still convinced exploiting \n# wave and particle like behaiviour through use of trigonometric and geometric\n# relationships is the key to pushing LLMs to the next level.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I was planning to demonstrate how straight forward it is to fine-tune a pretrained\n# model such as BERT or RoBERTa etc. however I figure it doens't really make\n# sense to reinvent the wheel so I will just give a quick conceptual overview\n\n# 1. Import transformers & datasets if needed\n# 2. Load tokenizer and model either directly from huggingface or from disk\n# 3. Tokenize your dataset using the datasets library or however you wish,\n# so long as it ends up as streamable from disk as would by the case with \n# a pyarrow dataset (native to huggingface effectiely) or a straight-forward\n# tensor dataset in torch or TF format depending on your framework of choice\n# 4. Use HF's trainer appropriate for the task at hand, this should correspond\n# to your '.from_pretrained' selection, i.e. your SequenceClassification choice\n# in your model loading step should mirror your trainers objective \n# (alternatively, and as I usually prefer, you can build the training loop yourself\n# including the Datasets behvaiour, i.e. on-the-fly tokenziation, streaming, or pre-tokenize\n# in memory, usually only a good choice with fine-tuning on smaller datasets)\n# 5. Train and validate like any other scenario. This is not really unique to\n# an NLP problem. \n# 6. If you weren't opting for checkpointing, save your pre-trained model, again\n# this is conditional on your framework of choice, also consider how you will be deploying\n# your model with regards to the format you choose. Ideally you want to save models\n# in a format that is compatible across both HF and your DL framework, and it is best to\n# choose a method that preserves the architecture as well as the weights if storage\n# is not a concern. \n\n# Points to consider:\n# - As you may have noticed, anyone who can read API documentation, and also read\n# books in general can and will be able to perform these steps given that \n# the tooling is open-source (as are the instruction manuals).\n\n# - Challenges are usually not with tooling. Bugs are dealt with by the library\n# maintainers very quickly. Problems arise when outcomes are radically different\n# to expectations, particulary amplified when the tooling and instructions are followed\n# closely. Interesting examples to ponder is if I gave you a million row CSV\n# with moview reviews except I assigned the labels using a uniform distribution \n# with a random seed based on the current datetime multiplied by the amount grass blades\n# in my backyard normalized to be between 1-5. So in essence, one cannot rely\n# on tooling alone. Garbage in, garbage out.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}